{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import IPython\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Evaluation and Selection</h1>\n",
    "\n",
    "<p>In this assignment we will introduce some techniques to evaluate the quality of a method and how to select good parameter values.</p>\n",
    "\n",
    "<p>We will be using the scikit built-in breast_cancer data set. It is binary classification problem where breast masses are classified as malignin (equal 0) or benign (equal 1).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples are 30 the names of the features in the data set are: \n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "data = dataset.data\n",
    "target = dataset.target\n",
    "\n",
    "###Find how many features we have and their names\n",
    "print 'The number of samples are',dataset.feature_names.size,'the names of the features in the data set are: '\n",
    "print dataset.feature_names\n",
    "\n",
    "#The columns 10 to 19 are measurements errors and we can drop them without affecting much the work done here\n",
    "###Remove the columns 10 to 19 in the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
       "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
       "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
       "       'worst concave points', 'worst symmetry', 'worst fractal dimension'], \n",
       "      dtype='|S23')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset.feature_names\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 20)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.delete(data, np.s_[10:20], axis=1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "data_scaled = scale(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2>Example on a Single Decision Tree</h2>\n",
    "\n",
    "<p>In this section we will introduce evaluation and paramtere selection techniques on a single decision tree.</p>\n",
    "\n",
    "<h4>Simple Evaluation</h4>\n",
    "<p>Evaluating the accuracy of a method can naively be done by splitting the data set in a training set and a test set.\n",
    "We train our classifier on the training set (obviously) and we evaluate the accuracy on the test set.<br>\n",
    "In scikit this is easily done by using the <i>.score()</i> functions of the classifier.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "###Split the data in train and test sets and the target in train_target and test_target (ratio 70%-30%)\n",
    "## Hint : by using the keyword \"random_state=0\" when you call train_test_split\n",
    "##        you make sure that the splits are the same for both data and target\n",
    "x_train, x_test, target_train, target_test = train_test_split(data_scaled, target, train_size=0.7, random_state=0)\n",
    "\n",
    "###Import a decision tree and train it on the training set with the default settings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dtr = tree.DecisionTreeClassifier()\n",
    "dtr.fit(x_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': False,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94152046783625731"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Compute the accuracy on the test set\n",
    "dtr.score(x_test,target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_pred = dtr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The accuracy is simply giving you the amount of samples that have been correctly classified<br>\n",
    "Other methods to measure the quality of the classifier are available. For instance one can use the F1 score. F1 score use the <i>precision</i> and <i>recall</i> (see https://en.wikipedia.org/wiki/Precision_and_recall) to evaluate the quality of a classification.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95238095238095233"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "#f1_score(<test targets>,<classifier prediction for the test set>,average='binary')\n",
    "\n",
    "f1 = f1_score(target_test,x_test_pred,average='binary')\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>It is also possible to have the detail of precision and recall for both classes :</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   malignin       0.88      0.97      0.92        63\n",
      "     benign       0.98      0.93      0.95       108\n",
      "\n",
      "avg / total       0.94      0.94      0.94       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#print classification_report(<test targets>,<classifier predictions for test set>,target_names=<target names>)\n",
    "print classification_report(target_test,x_test_pred,target_names= ['malignin','benign'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We started this study by doing a random separation for the train/test sets. Actually all scores of tests performed so far depend on this separation.</p>\n",
    "\n",
    "<h4> <u>QUESTION 1 :</u> Explain why all scores are specific to our first sets split.</h4>\n",
    "<p><i>Type your answer here</i></p>\n",
    "        -The function, train_test_split, does the spliting of the data into subsets randomly (using pseudo-random number generator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.88421053,  0.94210526,  0.88359788])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "###use the cross_val_score function on the whole dataset\n",
    "cv = cross_val_score(dtr,data,target)\n",
    "cv\n",
    "\n",
    "#When calling the cross_val_score it returns one score per fold\n",
    "#As by default the function uses a three-fold separation you have three value\n",
    "###Compute and print the mean and the standard deviation of the cross_val_score function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90330455769052254"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027437381937170734"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Several techniques exist to divide the data set in folds (see http://scikit-learn.org/stable/modules/cross_validation.html for more details).</p>\n",
    "<p>Nonetheless, it is worth mentioning another technique : the ShuffleSplit. This technique generates a pre-defined number of independent train/test dataset splits. Samples are first shuffled and then split into a pair of train and test sets.</p>\n",
    "<p>This can be implemented as follow :</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.89473684,  0.94736842,  0.87301587])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import ShuffleSplit\n",
    "cv_ss = ShuffleSplit(data.shape[0],n_iter=5,test_size=0.4,random_state=0)\n",
    "\n",
    "###Use again the cross_val_score function and set \"cv=cv_ss\"\n",
    "cv=cv_ss\n",
    "cv = cross_val_score(dtr,data,target)\n",
    "cv\n",
    "\n",
    "###Compute again the mean and the standard deviation of the output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9050403787245892"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031216421960660014"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> <u>QUESTION 2 :</u> Are results very different?</h4>\n",
    "<p><i>Type your answer here</i></p>\n",
    "        - The results are not very different\n",
    "<h3>Finding Optimal Parameters</h3>\n",
    "\n",
    "<p>In the previous section we have use the default settings for our classifiers but this is usually not necessarily the most optimal choice.</p>\n",
    "<p>In this section we will introduce tools to find good parameters value.</p>\n",
    "\n",
    "<h4>Grid Search - a brute force approach</h4>\n",
    "<p>A decision tree has several parameters we can change to optimize the classification. Scikit offers the possibility to investigate several parameters using <i>GridSearchCV</i>. You simply need to define a \"parameter grid\" (a dictionary in python) that defines the parameters values you want to try and feed it to a GridSearchCV object :</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'splitter': ['best', 'random'], 'criterion': ['entropy', 'gini'], 'max_leaf_nodes': [None, 7, 8, 25, 15, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "###Example of a parameter grid dictionary, run it once and then include more parameters in p_grid\n",
    "p_grid=dict({'criterion':['entropy','gini'],'splitter':['best','random'],'max_leaf_nodes':[None,7,8,25,15,10]})\n",
    "\n",
    "#grd = GridSearchCV(<classifier>,cv=3,param_grid=<dictionary of parameters to investigate>)\n",
    "#grd.fit(<training set>,<train set targets>)\n",
    "grd = GridSearchCV(dtr,cv=3,param_grid= p_grid)\n",
    "grd.fit(x_train,target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> <u>QUESTION 2 :</u> What does the \"CV\" at the end of GridSearchCV stands for? What is it telling you?</h4>\n",
    "<p><i>Type your answer here</i></p>\n",
    "        -Cross Validation. \n",
    "        It tells us that the parameters of the estimator used are optimized by cross-validated grid-search over a parameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_leaf_nodes': 10, 'splitter': 'best'}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You can ask for the best parameters found by running the following command\n",
    "grd.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': None,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': False,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And creat directly a new classifier with the optimal parameters by running\n",
    "new_dtr = grd.best_estimator_\n",
    "\n",
    "###Check the \"new_dtr\" parameters\n",
    "new_dtr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=10, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Now train the new classifier\n",
    "new_dtr.fit(x_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97989949748743721"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Compute its accuracy\n",
    "new_dtr.score(x_train,target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94736842105263153"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dtr.score(x_test,target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "  malignant       0.88      0.97      0.92        63\n",
      "     benign       0.98      0.93      0.95       108\n",
      "\n",
      "avg / total       0.94      0.94      0.94       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###print the classification report\n",
    "print classification_report(target_test,x_test_pred,target_names= dataset.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Learning and Validation Curves</h4>\n",
    "<p> Scikit provides additional tools to tune our algorithm.<br>\n",
    "One useful tool is the learning curve. It gives the cross-validated training and test scores for different training sets sizes.\n",
    "We can use it on the previously defined new classifier \"new_dtr\" :</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.learning_curve import learning_curve\n",
    "\n",
    "###Compute the learning curve\n",
    "#<number of elements in train>,<train score>,<test score> = learning_curve(<classifier>,<data>,<targets>,train_sizes=<liste of training sizes>,cv=3)\n",
    "train_size,train_score,test_score = learning_curve(new_dtr,x_train,target_train,train_sizes= [20,60,120,160,200,240,263],cv=3,n_jobs=1)\n",
    "\n",
    "\n",
    "#The list of training sizes can be absolute numbers or amount if between (0,1]\n",
    "\n",
    "###Visualize the learning curve (don't forget labels, title,legend,etc)\n",
    "\n",
    "#You should see why I chose a 70%-30% ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 20,  60, 120, 160, 200, 240, 263])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        ,  1.        ],\n",
       "       [ 1.        ,  1.        ,  1.        ],\n",
       "       [ 1.        ,  1.        ,  1.        ],\n",
       "       [ 1.        ,  1.        ,  1.        ],\n",
       "       [ 1.        ,  1.        ,  0.995     ],\n",
       "       [ 0.9875    ,  0.99583333,  0.9875    ],\n",
       "       [ 0.98098859,  0.99619772,  0.99239544]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.92481203,  0.90225564,  0.90909091],\n",
       "       [ 0.85714286,  0.90977444,  0.90151515],\n",
       "       [ 0.93233083,  0.90225564,  0.92424242],\n",
       "       [ 0.93233083,  0.90977444,  0.93939394],\n",
       "       [ 0.92481203,  0.89473684,  0.91666667],\n",
       "       [ 0.95488722,  0.88721805,  0.88636364],\n",
       "       [ 0.93984962,  0.93233083,  0.90909091]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xac835cac>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmMAAAFNCAYAAABMhmimAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xac8425ec>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('LVC')\n",
    "plt.ylim(0.01,1.2)\n",
    "\n",
    "plt.xlabel(\"Train size\")\n",
    "plt.ylabel(\"train Score\")\n",
    "train_score_mean = np.mean(train_score, axis=1)\n",
    "train_score_std = np.std(train_score, axis=1)\n",
    "test_score_mean = np.mean(test_score, axis=1)\n",
    "test_score_std = np.std(test_score, axis=1)\n",
    "\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.plot(train_size, train_score_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "plt.plot(train_size, test_score_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> <u>QUESTION 3 :</u> Why isn't the training score equal to one?</h4>\n",
    "<p><i>Type your answer here</i></p>\n",
    "        -It is because of randomness in the cross validation\n",
    "<p>A second tool meant to investigate a specific parameter influence on scores is the <i>validation curve</i>. It is basically like a gridsearch with a single parameter. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xac6a0c6c>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAz0AAAH0CAYAAAAXEEMgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvMUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xac90f2ac>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.learning_curve import validation_curve\n",
    "\n",
    "#Just an example\n",
    "train_score,test_score = validation_curve(new_dtr,data,target,param_name='max_depth',param_range=np.arange(2,8),cv=3)\n",
    "\n",
    "\n",
    "###Plot the validation curve\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.title('Validation Curve for DecisionTreeClassifier')\n",
    "plt.xlabel(\"Parameter Range\")\n",
    "plt.ylabel(\"Score\")\n",
    "train_score_mean = np.mean(train_score, axis=1)\n",
    "train_score_std = np.std(train_score, axis=1)\n",
    "test_score_mean = np.mean(test_score, axis=1)\n",
    "test_score_std = np.std(test_score, axis=1)\n",
    "plt.grid()\n",
    "plt.plot(np.arange(2,8), train_score_mean, label=\"Training score\", color=\"b\")\n",
    "plt.plot(np.arange(2,8), test_score_mean, label=\"Cross-validation score\",\n",
    "             color=\"g\")\n",
    "plt.ylim(0.6, 1.2)\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Application - Evaluating the Random Forest classifier and the SVC</h3>\n",
    "\n",
    "<p>In the following you will apply the evaluation and optimization tools to compare the Random Forest technique and the SVC technique.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Import the \"RandomForestClassifier\" classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "###Train it on the training set\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Import the \"SVC\" classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import scale\n",
    "#svc = SVC(kernel='rbf',probability=True)\n",
    "\n",
    "###Train it on the training set  (don't forget to scale it!)\n",
    "svc = SVC()\n",
    "paul= scale(x_train)\n",
    "svc.fit(scale(paul),target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': None,\n",
       " 'degree': 3,\n",
       " 'gamma': 'auto',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "svc.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Before evaluating the performance of both classifiers we will first determine the best values for their parameters</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_features': ['sqrt', 'log2', 'auto'], 'criterion': ['entropy', 'gini']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Using the grid search optimize the Random Forest Classifier\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "p_grid=dict({'criterion':['entropy','gini'],'max_features':['sqrt','log2','auto']})\n",
    "p_grd = GridSearchCV(rfc,cv=3,param_grid=p_grid)\n",
    "p_grd.fit(x_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_features': 'sqrt'}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "p_grd.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create a new Random Forest Classifier using the best parameters found\n",
    "new_p = p_grd.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "new_rfc = RandomForestClassifier()\n",
    "new_rfc.fit(x_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99246231155778897"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rfc.score(x_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'kernel': ['rbf', 'linear', 'poly', 'sigmoid'], 'C': [1.0, 10.0, 100.0], 'degree': [3, 1, 5], 'tol': [0.01, 0.03, 0.05]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Using the grid search optimize the SVC Classifier\n",
    "#(!don't forget to scale the data!)\n",
    "\n",
    "svc_p =dict({'C':[1.0,10.0, 100.0],'degree':[3,1,5],'kernel':['rbf', 'linear', 'poly','sigmoid'],\n",
    "               'tol':[0.01, 0.03, 0.05]})\n",
    "svc_p = GridSearchCV(svc,cv=3,param_grid=svc_p)\n",
    "svc_p.fit(scale(x_train),target_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Create a new Random Forest Classifier using the best parameters found\n",
    "rfc2 = svc_p.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'degree': 1, 'kernel': 'poly', 'tol': 0.01}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_p.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now we have optimized out two classifier we can compare how they perform</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95125 0.0169558249578\n",
      "0.9825 0.00467707173347\n"
     ]
    }
   ],
   "source": [
    "###Compute and the accuracy of both classifiers on the training set using the cross_val_score\n",
    "# (!scale for SVC!)\n",
    "#rfc2 = cross_val_score(rfc,data,target)\n",
    "#svc2 = cross_val_score(svc,data,target)\n",
    "\n",
    "#RandomForestClassifier\n",
    "cv_ss = ShuffleSplit(x_train.shape[0],n_iter=5,test_size=0.4,random_state=0)\n",
    "cvsn = cross_val_score(new_rfc, x_train, target_train, cv=cv_ss)\n",
    "\n",
    "#SVC\n",
    "cv_ss = ShuffleSplit(scale(x_train).shape[0],n_iter=5,test_size=0.4,random_state=0)\n",
    "cvsp = cross_val_score(rfc2, scale(x_train), target_train, cv=cv_ss)\n",
    "\n",
    "\n",
    "\n",
    "#Print the results (average and std)\n",
    "\n",
    "print np.mean(cvsn), np.std(cvsn)\n",
    "print np.mean(cvsp), np.std(cvsp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> <u>QUESTION 4 :</u> Which classifier gives the best accuracy?</h4>\n",
    "<p><i>Type your answer here</i></p>\n",
    "- It is SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "  malignant       0.91      0.97      0.94        63\n",
      "     benign       0.98      0.94      0.96       108\n",
      "\n",
      "avg / total       0.95      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###Print the Classification report for the Random Forest Classifier\n",
    "rfc_pred = rfc.predict(x_test)\n",
    "print classification_report(target_test,rfc_pred,target_names= dataset.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "  malignant       0.88      0.97      0.92        63\n",
      "     benign       0.98      0.93      0.95       108\n",
      "\n",
      "avg / total       0.94      0.94      0.94       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###Do the same for the SVC classifier\n",
    "svc_pred = svc.predict(x_test)\n",
    "print classification_report(target_test,x_test_pred,target_names= dataset.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> <u>QUESTION 5 :</u> Analyze the last two classification reports.</h4>\n",
    "<p><i>Type your answer here</i></p>\n",
    "        -From the above two classification_reports, we can see that SVC gives us more accurate results, the everage precision of 0.98 as compared to Random Forest Classifier which is 0.94.\n",
    "<h4> <u>QUESTION 6 :</u> Recall the classification report from the optimized decision tree to conclude on the best algorithm to chose to efficiently detect malignant masses.</h4>\n",
    "<p><i>Type your answer here</i></p>\n",
    "        -From the optimized decision tree we have the accuracy of SVC as \n",
    ": 0.98 (+/- 0.004) and the accuracy of Random Forest as : 0.95 (+/- 0.01). The results can allow us to confinently choose SVC as our preferred algorithm to detect malignant masses\n",
    "<h4> <u>BONUS :</u> Repeat the optimization and evalution procedure with the k-nearest neighbors approach.</h4>\n",
    "<p><i>Type your answer here</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'p': [2, 4, 6], 'algorithm': ['ball_tree', 'kd_tree', 'brute'], 'n_neighbors': [7, 15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn_grid=dict({'algorithm':['ball_tree','kd_tree','brute'], 'p':[2,4,6],\n",
    "             'n_neighbors':[7,15]})\n",
    "\n",
    "knn_grd = GridSearchCV(knn,cv=3,param_grid=knn_grid)\n",
    "knn_grd.fit(x_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_knn = knn_grd.best_estimator_\n",
    "new_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN: 0.97 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "cv_ss = ShuffleSplit(x_train.shape[0],n_iter=5,test_size=0.4,random_state=0)\n",
    "cvs4 = cross_val_score(new_knn, x_train, target_train, cv=cv_ss)\n",
    "print(\"Accuracy of KNN: %0.2f (+/- %0.2f)\" % (cvs4.mean(), cvs4.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "  malignant       0.95      0.94      0.94        63\n",
      "     benign       0.96      0.97      0.97       108\n",
      "\n",
      "avg / total       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(target_test, new_knn.predict(x_test), target_names=['malignant', 'benign'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
